{{ template "chart.header" . }}

{{ template "chart.deprecationWarning" . }}

{{ template "chart.badgesSection" . }}

{{ template "chart.description" . }}

{{ template "chart.homepageLine" . }}

{{ template "chart.maintainersSection" . }}

{{ template "chart.sourcesSection" . }}

{{ template "chart.requirementsSection" . }}

## Features

- **Dual Deployment Pattern**: Implements the recommended OpenTelemetry architecture with both agent (DaemonSet) and cluster receiver (Deployment) components
- **Agent (DaemonSet)**: Collects host metrics, Kubernetes objects, and application telemetry from each node
- **Cluster Receiver (Deployment)**: Collects cluster metrics and events using the Kubernetes API server
- **Secret Management**: Configurable secrets for OpenTelemetry configuration with external secret support
- **RBAC Support**: Comprehensive service account and role-based access control
- **Resource Management**: Configurable resource limits and requests for both components
- **Host Metrics Collection**: Built-in support for node-level metrics collection
- **Kubernetes Objects Monitoring**: Automatic collection of pods, services, and other K8s resources
- **Comprehensive Observability**: Logs, metrics, and traces collection with intelligent defaults
- **Security First**: Built-in security best practices and credential management
- **Production Ready**: Optimized configurations for production environments
- **Flexible Configuration**: Merge-based or full custom configuration options

## Architecture

The chart implements the recommended OpenTelemetry architecture with two main components:

### Agent (DaemonSet)

- Runs on every node in the cluster
- Collects host metrics, Kubernetes objects, and application telemetry
- Forwards data to the cluster receiver or external backends
- Uses host networking for optimal performance (configurable)

**Default Receivers:**
- **Host Metrics**: CPU, memory, disk, filesystem, load, optional network and process metrics
- **Kubelet Stats**: Node and pod metrics via kubelet
- **Prometheus**: Scrapes application metrics from pods with `prometheus.io/scrape: true` annotation
- **OTLP**: Receives traces, metrics, and logs
- **Jaeger** and **Zipkin**: Receive traces via Jaeger and Zipkin protocols
- **File Logs**: Collects container logs from `/var/log/pods/*/*/*.log` (controlled by `agent.collectLogs`)

**Default Processors:**
- **K8s Attributes**: Enriches telemetry with Kubernetes metadata and selected pod labels
- **Memory Limiter**: Prevents memory issues (80% limit, 25% spike limit)
- **Batch**: Batches telemetry for efficient processing
- **Cumulative To Delta**: Converts cumulative counters to delta where applicable
- **Resource**: Adds attributes including `k8s.cluster.name` (from `clusterName`)

**Default Exporters:**
- **OTLP/Tsuga**: Forwards all telemetry to Tsuga endpoint with authentication

**Service Pipelines:**
- **Logs**: `otlp`, `filelog` → `k8sattributes`, `memory_limiter`, `batch`, `resource` → `otlphttp/tsuga`
- **Metrics**: `otlp`, `prometheus`, `kubeletstats`, `spanmetrics`, `hostmetrics` → `k8sattributes`, `memory_limiter`, `batch`, `cumulativetodelta`, `resource` → `otlphttp/tsuga`
- **Traces**: `otlp`, `jaeger`, `zipkin` → `k8sattributes`, `memory_limiter`, `batch`, `resource` → `otlphttp/tsuga`, `spanmetrics`

### Cluster Receiver (Deployment)

- Collects cluster metrics and events using the Kubernetes API server

**Default Receivers:**
- **Kubernetes Cluster**: Collects cluster-level metrics and entity events via `k8s_cluster`

**Default Processors:**
- **Resource**: Adds deployment/cluster attributes (defaults include `k8s.cluster.name`)
- **K8s Attributes**: Optional Kubernetes metadata extraction

**Default Exporters:**
- **OTLP**: Forwards to Tsuga endpoint

**Service Pipelines:**
- **Metrics**: `k8s_cluster` → `resource` → `otlphttp/tsuga`
- **Entity Events (Logs)**: `k8s_cluster` → `resource` → `otlphttp/tsuga`

## Quick Start

Use the deploy script

```bash
./deploy.sh
```

## Installation

### Install the OpenTelemetry Operator

First, install the OpenTelemetry Operator in your cluster:

```bash
kubectl apply -f https://github.com/open-telemetry/opentelemetry-operator/releases/latest/download/opentelemetry-operator.yaml
```

## Auto-instrumentation (APM)

This chart can optionally create an OpenTelemetry Operator `Instrumentation` resource via `autoInstrumentation`.

### Prerequisites

- The **OpenTelemetry Operator** must be installed in the cluster (see Installation above).
- Your workloads must opt-in via **pod annotations** (examples below).

### Enable and configure

Create an `Instrumentation` CR with your desired configuration:

```yaml
autoInstrumentation:
  enabled: true
  # apiVersion depends on your operator version
  apiVersion: opentelemetry.io/v1alpha1
  spec:
    exporter:
      endpoint: http://otel-collector:4318
    propagators: [tracecontext, baggage]
    sampler:
      type: parentbased_traceidratio
      argument: "1.0"
    # Configure the language(s) you plan to inject
    java:
      image: ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-java:2.10.0
```

### Inject into workloads

Annotate your workload pods to enable injection:

```yaml
spec:
  template:
    metadata:
      annotations:
        instrumentation.opentelemetry.io/inject-java: "true"
```

Supported annotation keys depend on language (examples):

- `instrumentation.opentelemetry.io/inject-java`
- `instrumentation.opentelemetry.io/inject-python`
- `instrumentation.opentelemetry.io/inject-nodejs`
- `instrumentation.opentelemetry.io/inject-dotnet`

### Install the Chart

#### Option 1: Using Chart Repository (Recommended)

```bash
# Add the repository
helm repo add tsuga-charts https://tsuga-dev.github.io/helm-charts/
helm repo update

# Install with Tsuga configuration
helm install my-otel-stack tsuga-charts/opentelemetry-kube-stack \
  --set secret.create=true \
  --set tsuga.otlpEndpoint="https://your-tsuga-endpoint.com" \
  --set tsuga.apiKey="your-api-key-here"
```

#### Option 2: Direct Installation

```bash
# Install directly from the chart directory
helm install my-otel-stack ./opentelemetry-kube-stack \
  --set secret.create=true \
  --set tsuga.otlpEndpoint="https://your-tsuga-endpoint.com" \
  --set tsuga.apiKey="your-api-key-here"
```

#### Option 3: Using Values File

```bash
# Create a values file
cat > my-values.yaml << EOF
tsuga:
  otlpEndpoint: "https://your-tsuga-endpoint.com"
  apiKey: "your-api-key-here"
secret:
  create: true
EOF

# Install with values file
helm install my-otel-stack ./opentelemetry-kube-stack -f my-values.yaml
```

## Configuration

{{ template "chart.valuesSection" . }}

## Contributing

### Development Setup

1. **Fork the repository**
2. **Clone your fork:**
   ```bash
   git clone https://github.com/tsuga-dev/helm-charts.git
   cd helm-charts/charts/opentelemetry-kube-stack
   ```
3. **Create a feature branch:**
   ```bash
   git checkout -b feature/your-feature-name
   ```
4. **Make your changes:**
   - Update templates in `templates/`
   - Update values in `values.yaml`
   - Add tests in `tests/`
   - Update documentation

### Testing

#### Unit Tests

```bash
# Run unit tests
make unittest

# Run specific test
helm test my-otel-stack
```

#### Integration Tests

```bash
# Run integration tests
make integration
# or
./tests/integration/test-deployment.sh
```

#### Security Tests

```bash
# Run security scan
make security
# or
./tests/security/security-scan.sh
```

#### Linting

```bash
# Lint templates
make lint
# or
helm lint .
```

#### Template Testing

```bash
# Test rendering
make template
# or
helm template test . --set tsuga.otlpEndpoint="test" --set tsuga.apiKey="test"
```

### Documentation

To update the parameter documentation in the README:

```bash
# Generate documentation using helm-docs
make docs
# or
helm-docs
```

This will automatically update the parameter reference section in the README based on comments in `values.yaml`.

### Code Style

- Use 2 spaces for YAML indentation
- Follow Helm best practices
- Add comments for complex logic
- Use descriptive variable names
- Follow semantic versioning
- Ensure all parameters in `values.yaml` have proper helm-docs comments (`# -- Description` and `# @default -- value`)

## License

This chart is licensed under the Apache 2.0 License. See the [LICENSE](LICENSE) file for details.

## Support

For support and questions:

- Create an issue in the repository
- Check the troubleshooting section above
- Review the OpenTelemetry documentation
- Join the OpenTelemetry community Slack
---
# Source: opentelemetry-kube-stack/templates/daemonset.yaml
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: example-opentelemetry-kube-stack-agent
  labels:
    app.kubernetes.io/name: opentelemetry-kube-stack
    app.kubernetes.io/instance: example
    app.kubernetes.io/component: agent
    app.kubernetes.io/part-of: opentelemetry-kube-stack
    app.kubernetes.io/managed-by: Helm
spec:
  mode: daemonset
  hostNetwork: true
  image: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-k8s
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 128Mi
  volumeMounts:
    - name: varlogpods
      mountPath: /var/log/pods
      readOnly: true
    - name: varlibdockercontainers
      mountPath: /var/lib/docker/containers
      readOnly: true
  volumes:
    - name: varlogpods
      hostPath:
        path: /var/log/pods
    - name: varlibdockercontainers
      hostPath:
        path: /var/lib/docker/containers
  serviceAccount: example-opentelemetry-kube-stack
  env:
    - name: TSUGA_OTLP_ENDPOINT
      valueFrom:
        secretKeyRef:
          name: otel-secret
          key: TSUGA_OTLP_ENDPOINT
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIP
    - name: TSUGA_API_KEY
      valueFrom:
        secretKeyRef:
          name: otel-secret
          key: TSUGA_API_KEY
  config:
    connectors:
      spanmetrics: {}
    extensions:
      health_check:
        endpoint: ${env:MY_POD_IP}:13133
    exporters:
      
      otlphttp/tsuga:
        endpoint: ${TSUGA_OTLP_ENDPOINT}
        headers:
          Authorization: Bearer ${TSUGA_API_KEY}
    receivers:
      
      # Agent receivers
      filelog:
        exclude: []
        include:
          - /var/log/pods/*/*/*.log
        include_file_name: false
        include_file_path: true
        operators:
          - id: container-parser
            max_log_size: 102400
            type: container
        retry_on_failure:
          enabled: true
        start_at: end
      jaeger:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:14250
          thrift_compact:
            endpoint: ${env:MY_POD_IP}:6831
          thrift_http:
            endpoint: ${env:MY_POD_IP}:14268
      kubeletstats:
        insecure_skip_verify: true
        auth_type: serviceAccount
        collection_interval: 20s
        endpoint: ${env:K8S_NODE_NAME}:10250
      hostmetrics:
        collection_interval: 10s
        scrapers:
          paging:
            metrics:
              system.paging.utilization:
                enabled: true
          cpu:
            metrics:
              system.cpu.utilization:
                enabled: true
          disk:
          filesystem:
            metrics:
              system.filesystem.utilization:
                enabled: true
          load:
          memory:
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
          http:
            endpoint: ${env:MY_POD_IP}:4318
      prometheus:
        config:
          scrape_configs:
            - job_name: opentelemetry-collector
              scrape_interval: 10s
              static_configs:
                - targets:
                    - ${env:MY_POD_IP}:8888
      zipkin:
        endpoint: ${env:MY_POD_IP}:9411
    processors:
      
      # Agent processors
      batch: {}
      k8sattributes:
        extract:
          metadata:
            - k8s.namespace.name
            - k8s.deployment.name
            - k8s.statefulset.name
            - k8s.daemonset.name
            - k8s.cronjob.name
            - k8s.job.name
            - k8s.node.name
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.pod.start_time
            - k8s.node.name
        filter:
          node_from_env_var: K8S_NODE_NAME
        passthrough: false
        pod_association:
          - sources:
            - from: resource_attribute
              name: k8s.pod.ip
          - sources:
            - from: resource_attribute
              name: k8s.pod.uid
          - sources:
            - from: connection
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      cumulativetodelta: {}
      resource:
        attributes:
        - key: k8s.cluster.name
          value: 
          action: upsert
    service:
      extensions:
      - health_check
      pipelines:
        
        # Agent pipelines
        logs:
          exporters:
            - otlphttp/tsuga
          processors:
            - k8sattributes
            - memory_limiter
            - batch
            - resource
          receivers:
            - otlp
            - filelog
        metrics:
          exporters:
            - otlphttp/tsuga
          processors:
            - k8sattributes
            - memory_limiter
            - batch
            - cumulativetodelta
            - resource
          receivers:
            - otlp
            - prometheus
            - kubeletstats
            - spanmetrics
            - hostmetrics
        traces:
          exporters:
            - otlphttp/tsuga
            - spanmetrics
          processors:
            - k8sattributes
            - memory_limiter
            - batch
            - resource
          receivers:
            - otlp
            - jaeger
            - zipkin
      telemetry:
        
        metrics:
          readers:
            - pull:
                exporter:
                  prometheus:
                    host: ${env:MY_POD_IP}
                    port: 8888

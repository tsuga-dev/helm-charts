---
# Source: opentelemetry-kube-stack/templates/daemonset.yaml
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: example-opentelemetry-kube-stack-agent
  labels:
    app.kubernetes.io/name: opentelemetry-kube-stack
    app.kubernetes.io/instance: example
    app.kubernetes.io/component: agent
    app.kubernetes.io/part-of: opentelemetry-kube-stack
    app.kubernetes.io/managed-by: Helm
  annotations:
    meta.helm.sh/release-name: "example"
    meta.helm.sh/release-namespace: "default"
spec:
  mode: daemonset
  hostNetwork: true
  image: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 128Mi
  volumeMounts:
    - name: hostfs
      mountPath: /hostfs
      readOnly: true
      mountPropagation: HostToContainer
  volumes:
    - name: hostfs
      hostPath:
        path: /
  serviceAccount: example-opentelemetry-kube-stack
  env:
    - name: TSUGA_OTLP_ENDPOINT
      valueFrom:
        secretKeyRef:
          name: otel-secret
          key: TSUGA_OTLP_ENDPOINT
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIP
    - name: TSUGA_API_KEY
      valueFrom:
        secretKeyRef:
          name: otel-secret
          key: TSUGA_API_KEY
    - name: NODE_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.hostIP
  config:
    receivers:
      hostmetrics:
        collection_interval: 10s
        root_path: /hostfs
        scrapers:
          cpu:
            metrics:
              system.cpu.utilization:
                enabled: true
          disk: null
          filesystem:
            metrics:
              system.filesystem.utilization:
                enabled: true
          load: null
          memory: null
          paging:
            metrics:
              system.paging.utilization:
                enabled: true
      jaeger:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:14250
          thrift_compact:
            endpoint: ${env:MY_POD_IP}:6831
          thrift_http:
            endpoint: ${env:MY_POD_IP}:14268
      kubeletstats:
        auth_type: serviceAccount
        collection_interval: 20s
        endpoint: ${env:NODE_IP}:10250
        insecure_skip_verify: true
      nginx:
        collection_interval: 10s
        endpoint: http://image-provider.default:8081/status
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
          http:
            endpoint: ${env:MY_POD_IP}:4318
      postgresql:
        endpoint: postgresql.default:5432
        metrics:
          postgresql.blks_hit:
            enabled: true
          postgresql.blks_read:
            enabled: true
          postgresql.deadlocks:
            enabled: true
          postgresql.tup_deleted:
            enabled: true
          postgresql.tup_fetched:
            enabled: true
          postgresql.tup_inserted:
            enabled: true
          postgresql.tup_returned:
            enabled: true
          postgresql.tup_updated:
            enabled: true
        password: otel
        tls:
          insecure: true
        username: root
      prometheus:
        config:
          scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 10s
            static_configs:
            - targets:
              - ${env:MY_POD_IP}:8888
      receiver_creator/logs:
        discovery:
          enabled: true
        receivers: null
        watch_observers:
        - k8s_observer
      redis:
        collection_interval: 10s
        endpoint: valkey-cart.default:6379
        username: valkey
      zipkin:
        endpoint: ${env:MY_POD_IP}:9411
    processors:
      batch: {}
      cumulativetodelta: {}
      k8sattributes:
        extract:
          annotations:
          - from: pod
            key: resource.opentelemetry.io/service.name
            tag_name: service.name
          - from: pod
            key: resource.opentelemetry.io/service.version
            tag_name: service.version
          - from: pod
            key: resource.opentelemetry.io/env
            tag_name: env
          - from: pod
            key: resource.opentelemetry.io/team
            tag_name: team
          labels:
          - from: pod
            key: resource.opentelemetry.io/service.name
            tag_name: service.name
          - from: pod
            key: resource.opentelemetry.io/service.version
            tag_name: service.version
          - from: pod
            key: resource.opentelemetry.io/env
            tag_name: env
          - from: pod
            key: resource.opentelemetry.io/team
            tag_name: team
          - from: pod
            key: resource.opentelemetry.io/test
            tag_name: test
          metadata:
          - k8s.namespace.name
          - k8s.deployment.name
          - k8s.statefulset.name
          - k8s.daemonset.name
          - k8s.cronjob.name
          - k8s.job.name
          - k8s.node.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.pod.start_time
        filter:
          node_from_env_var: K8S_NODE_NAME
        passthrough: false
        pod_association:
        - sources:
          - from: resource_attribute
            name: k8s.pod.ip
        - sources:
          - from: resource_attribute
            name: k8s.pod.uid
        - sources:
          - from: connection
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      resource:
        attributes:
        - action: upsert
          key: k8s.cluster.name
          value: null
    exporters:
      otlphttp/tsuga:
        endpoint: ${TSUGA_OTLP_ENDPOINT}
        headers:
          Authorization: Bearer ${TSUGA_API_KEY}
    extensions:
      health_check:
        endpoint: ${env:MY_POD_IP}:13133
      k8s_observer:
        auth_type: serviceAccount
        node: ${env:K8S_NODE_NAME}
        observe_ingresses: true
        observe_nodes: true
        observe_pods: true
        observe_services: true
    connectors:
      spanmetrics:
        calls_dimensions:
        - default: /ping
          name: http.url
        dimensions:
        - default: GET
          name: http.method
        - name: http.status_code
    service:
      extensions:
      - health_check
      - k8s_observer
      pipelines:
        logs:
          exporters:
          - otlphttp/tsuga
          processors:
          - k8sattributes
          - memory_limiter
          - batch
          - resource
          receivers:
          - otlp
          - receiver_creator/logs
        metrics:
          exporters:
          - otlphttp/tsuga
          processors:
          - k8sattributes
          - memory_limiter
          - batch
          - cumulativetodelta
          - resource
          receivers:
          - otlp
          - prometheus
          - kubeletstats
          - spanmetrics
          - hostmetrics
          - postgresql
          - redis
          - nginx
        traces:
          exporters:
          - otlphttp/tsuga
          - spanmetrics
          processors:
          - k8sattributes
          - memory_limiter
          - batch
          - resource
          receivers:
          - otlp
          - jaeger
          - zipkin
      telemetry:
        metrics:
          readers:
          - pull:
              exporter:
                prometheus:
                  host: ${env:MY_POD_IP}
                  port: 8888
